import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn import set_config 
import random


# Calling the data set
data = pd.read_excel("merged_output.xlsx", header=None)
print(data.shape)
data


#Deviding the data as input and label
X_train= data.iloc[:,24:]
y_train=data.iloc[:,:24]

print("shape of X train", X_train.shape)
print("shape of y train", y_train.shape)


#Calling the test data 
X_test= pd.read_excel('/Users/berkayersus/Desktop/test_data.xlsx')
print(X_test.shape)  
X_test

# use the same scaler for test and train data, and no need to scale y

scaler = StandardScaler() 
# scaler = MinMaxScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)



# y_train is 24 columns, each column is a target variable. RF for each column.

from sklearn.model_selection import cross_val_score

y_test_pred = np.zeros((X_test.shape[0], y_train.shape[1]))


# RF for each column
for i in range(y_train.shape[1]):
    print("training for column", i)
    y = y_train.iloc[:,i]
    rf = RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=0, max_features=7)
    # cross validation, built-in shuffle
    scores = cross_val_score(rf, scaled_X_train, y, cv=24, n_jobs=-1)
    print("scores", scores)
    print("mean score", np.mean(scores))
    rf.fit(scaled_X_train, y)

    # predict for test data
    y_pred = rf.predict(scaled_X_test)
    y_test_pred[:,i] = y_pred




# print the predicted values
predict = y_test_pred
print("predicted values")
print(predict)
